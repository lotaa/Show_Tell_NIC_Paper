{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVmPVs3bbciZ49yiAd5Lj2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "49a112ea42194774acb61692112608e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d5ee660faba4e6ea239cc15f298e9c9",
              "IPY_MODEL_c42b4fe7040245769100d2af492a68ee",
              "IPY_MODEL_713ce337c8cb45c28adca4712cef8a55"
            ],
            "layout": "IPY_MODEL_b5587e72627149b6bbd8a4e10d93cc36"
          }
        },
        "9d5ee660faba4e6ea239cc15f298e9c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32ed01206d0e429087432c81b35e47e5",
            "placeholder": "​",
            "style": "IPY_MODEL_ec273f3f15794fd88637f096ce21e7ae",
            "value": ""
          }
        },
        "c42b4fe7040245769100d2af492a68ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40f4fba9a62b40d18a3a5fcc8001fb94",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7846f444656b4c0194a76d0fbcf2df3a",
            "value": 0
          }
        },
        "713ce337c8cb45c28adca4712cef8a55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e8e6a74a12145099670908ebb0e4850",
            "placeholder": "​",
            "style": "IPY_MODEL_ea1f9eae1b3a4860b315e97e5f6d11c1",
            "value": " 0/? [00:00&lt;?, ?it/s]"
          }
        },
        "b5587e72627149b6bbd8a4e10d93cc36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32ed01206d0e429087432c81b35e47e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec273f3f15794fd88637f096ce21e7ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40f4fba9a62b40d18a3a5fcc8001fb94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "7846f444656b4c0194a76d0fbcf2df3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e8e6a74a12145099670908ebb0e4850": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea1f9eae1b3a4860b315e97e5f6d11c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lotaa/Show_Tell_NIC_Paper/blob/main/ImplementationOfPaper_ShowAndTell_NLC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETmn5dN9XTqn",
        "outputId": "30a5415b-8853-4da7-c1e5-ad28182aaec8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install TensorFlow\n",
        "!pip install Keras\n",
        "!pip install pillow\n",
        "!pip install NumPy\n",
        "#!Pip install jupyterlab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OLmW8V4b-eS",
        "outputId": "9aedd888-f48a-4b59-fc33-550e7033fd11"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: TensorFlow in /usr/local/lib/python3.9/dist-packages (2.11.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from TensorFlow) (0.31.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from TensorFlow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from TensorFlow) (1.51.3)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from TensorFlow) (2.11.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from TensorFlow) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from TensorFlow) (4.5.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from TensorFlow) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from TensorFlow) (3.8.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.9/dist-packages (from TensorFlow) (2.11.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from TensorFlow) (1.15.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from TensorFlow) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from TensorFlow) (67.6.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from TensorFlow) (1.24.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from TensorFlow) (1.16.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from TensorFlow) (23.3.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from TensorFlow) (2.2.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from TensorFlow) (0.4.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from TensorFlow) (1.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from TensorFlow) (15.0.6.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from TensorFlow) (23.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from TensorFlow) (2.11.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->TensorFlow) (0.40.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->TensorFlow) (2.16.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->TensorFlow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->TensorFlow) (2.2.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->TensorFlow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->TensorFlow) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->TensorFlow) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->TensorFlow) (2.27.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->TensorFlow) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->TensorFlow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->TensorFlow) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->TensorFlow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->TensorFlow) (6.1.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->TensorFlow) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->TensorFlow) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->TensorFlow) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->TensorFlow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->TensorFlow) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->TensorFlow) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->TensorFlow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->TensorFlow) (3.2.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.9/dist-packages (2.11.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (8.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NQlxVWq2XTgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install NumPy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzAt7fkFWUh0",
        "outputId": "b16e6587-2d73-4db2-8402-b10efe13929c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: NumPy in /usr/local/lib/python3.9/dist-packages (1.24.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "49a112ea42194774acb61692112608e3",
            "9d5ee660faba4e6ea239cc15f298e9c9",
            "c42b4fe7040245769100d2af492a68ee",
            "713ce337c8cb45c28adca4712cef8a55",
            "b5587e72627149b6bbd8a4e10d93cc36",
            "32ed01206d0e429087432c81b35e47e5",
            "ec273f3f15794fd88637f096ce21e7ae",
            "40f4fba9a62b40d18a3a5fcc8001fb94",
            "7846f444656b4c0194a76d0fbcf2df3a",
            "6e8e6a74a12145099670908ebb0e4850",
            "ea1f9eae1b3a4860b315e97e5f6d11c1"
          ]
        },
        "id": "sx07qqcLsHzh",
        "outputId": "be8ed8eb-0a56-4988-a46a-71372fcb2174"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-4922871b547d>:19: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  tqdm().pandas()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49a112ea42194774acb61692112608e3"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import string\n",
        "from pickle import dump\n",
        "from pickle import load\n",
        "from keras.applications.xception import Xception #to get pre-trained model Xception\n",
        "from keras.applications.xception import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.text import Tokenizer #for text tokenization\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "#from keras.layers.merge import add\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, Dense#Keras to build our CNN and LSTM\n",
        "from keras.layers import LSTM, Embedding, Dropout\n",
        "from tqdm import tqdm_notebook as tqdm #to check loop progress\n",
        "tqdm().pandas()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the document file into memory\n",
        "def load_fp(filename):\n",
        "  # Open file to read\n",
        "   file = open(filename, 'r')\n",
        "   text = file.read()\n",
        "   file.close()\n",
        "   return text\n",
        "# get all images with their captions\n",
        "def img_capt(filename):\n",
        "   file = load_doc(filename)\n",
        "   captions = file.split('n')\n",
        "   descriptions ={}\n",
        "   for caption in captions[:-1]:\n",
        "       img, caption = caption.split('t')\n",
        "       if img[:-2] not in descriptions:\n",
        "          descriptions[img[:-2]] = [ caption ]\n",
        "       else:\n",
        "            descriptions[img[:-2]].append(caption)\n",
        "   return descriptions\n",
        "#Data cleaning function will convert all upper case alphabets to lowercase, removing punctuations and words containing numbers\n",
        "def txt_clean(captions):\n",
        "   table = str.maketrans('','',string.punctuation)\n",
        "   for img,caps in captions.items():\n",
        "       for i,img_caption in enumerate(caps):\n",
        "           img_caption.replace(\"-\",\" \")\n",
        "           descp = img_caption.split()\n",
        "          #uppercase to lowercase\n",
        "           descp = [wrd.lower() for wrd in descp]\n",
        "          #remove punctuation from each token\n",
        "           descp = [wrd.translate(table) for wrd in descp]\n",
        "          #remove hanging 's and a\n",
        "           descp = [wrd for wrd in descp if(len(wrd)>1)]\n",
        "          #remove words containing numbers with them\n",
        "           descp = [wrd for wrd in descp if(wrd.isalpha())]\n",
        "          #converting back to string\n",
        "           img_caption = ' '.join(desc)\n",
        "           captions[img][i]= img_caption\n",
        "   return captions"
      ],
      "metadata": {
        "id": "yfXCtvPgc8YQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def txt_vocab(descriptions):\n",
        "  # To build vocab of all unique words\n",
        "   vocab = set()\n",
        "   for key in descriptions.keys():\n",
        "       [vocab.update(d.split()) for d in descriptions[key]]\n",
        "   return vocab\n",
        "#To save all descriptions in one file\n",
        "def save_descriptions(descriptions, filename):\n",
        "   lines = list()\n",
        "   for key, desc_list in descriptions.items():\n",
        "       for desc in desc_list:\n",
        "           lines.append(key + 't' + desc )\n",
        "   data = \"n\".join(lines)\n",
        "   file = open(filename,\"w\")\n",
        "   file.write(data)\n",
        "   file.close()\n",
        "# Set these path according to project folder in you system, like i create a folder with my name shikha inside D-drive\n",
        "dataset_text = \"Image Caption GeneratorFlickr_8k_text\"\n",
        "dataset_images = \"Image Caption GeneratorFlicker8k_Dataset\"\n",
        "#to prepare our text data\n",
        "filename = dataset_text + \"/\" + \"Flickr8k.token.txt\"\n",
        "#loading the file that contains all data\n",
        "#map them into descriptions dictionary \n",
        "descriptions = img_capt(filename)\n",
        "print(\"Length of descriptions =\" ,len(descriptions))\n",
        "#cleaning the descriptions\n",
        "clean_descriptions = txt_clean(descriptions)\n",
        "#to build vocabulary\n",
        "vocabulary = txt_vocab(clean_descriptions)\n",
        "print(\"Length of vocabulary = \", len(vocabulary))\n",
        "#saving all descriptions in one file\n",
        "save_descriptions(clean_descriptions, \"descriptions.txt\")"
      ],
      "metadata": {
        "id": "OUUJP9spcEpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model = Xception( include_top=False, pooling='avg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH-IzxI4fN7i",
        "outputId": "4833ea5c-dada-41a3-f4a1-bbc8f5183569"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83683744/83683744 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(directory):\n",
        "    model = Xception( include_top=False, pooling='avg' )\n",
        "    features = {}\n",
        "    for pic in tqdm(os.listdir(dirc)):\n",
        "      file = dirc + \"/\" + pic\n",
        "      image = Image.open(file)\n",
        "      image = image.resize((299,299))\n",
        "      image = np.expand_dims(image, axis=0)\n",
        "      #image = preprocess_input(image)\n",
        "      image = image/127.5\n",
        "      image = image - 1.0\n",
        "      feature = model.predict(image)\n",
        "      features[img] = feature\n",
        "    return features"
      ],
      "metadata": {
        "id": "Lh75tgLiiQRz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2048 feature vector\n",
        "features = extract_features(dataset_images)\n",
        "dump(features, open(\"features.p\",\"wb\"))\n",
        "#to directly load the features from the pickle file.\n",
        "features = load(open(\"features.p\",\"rb\"))"
      ],
      "metadata": {
        "id": "SlSK0zHij2Pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the data\n",
        "def load_photos(filename):\n",
        "   file = load_doc(filename)\n",
        "   photos = file.split(\"n\")[:-1]\n",
        "   return photos\n",
        "\n",
        "\n",
        "\n",
        "def load_clean_descriptions(filename, photos):\n",
        "  #loading clean_descriptions\n",
        "   file = load_doc(filename)\n",
        "   descriptions = {}\n",
        "   for line in file.split(\"n\"):\n",
        "      words = line.split()\n",
        "      if len(words)<1 :\n",
        "        continue\n",
        "   image, image_caption = words[0], words[1:]\n",
        "   if image in photos:\n",
        "    if image not in descriptions:\n",
        "       descriptions[image] = []\n",
        "       desc = ' ' + \" \".join(image_caption) + ' '\n",
        "       descriptions[image].append(desc)\n",
        "   return descriptions\n",
        "\n",
        "\n",
        "\n",
        "def load_features(photos):\n",
        "  #loading all features\n",
        "   all_features = load(open(\"features.p\",\"rb\"))\n",
        "  #selecting only needed features\n",
        "   features = {k:all_features[k] for k in photos}\n",
        "   return features\n",
        "\n",
        "filename = dataset_text + \"/\" + \"Flickr_8k.trainImages.txt\"\n",
        "\n",
        "#train = loading_data(filename)\n",
        "train_imgs = load_photos(filename)\n",
        "train_descriptions = load_clean_descriptions(\"descriptions.txt\", train_imgs)\n",
        "train_features = load_features(train_imgs)"
      ],
      "metadata": {
        "id": "LR-R3-P35CkW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert dictionary to clear list of descriptions\n",
        "def dict_to_list(descriptions):\n",
        "   all_desc = []\n",
        "   for key in descriptions.keys():\n",
        "      [all_desc.append(d) for d in descriptions[key]]\n",
        "   return all_desc\n",
        "#creating tokenizer class\n",
        "#this will vectorise text corpus\n",
        "#each integer will represent token in dictionary\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "def create_tokenizer(descriptions):\n",
        "   desc_list = dict_to_list(descriptions)\n",
        "   tokenizer = Tokenizer()\n",
        "   tokenizer.fit_on_texts(desc_list)\n",
        "   return tokenizer\n",
        "\n",
        "\n",
        "# give each word an index, and store that into tokenizer.p pickle file\n",
        "tokenizer = create_tokenizer(train_descriptions)\n",
        "dump(tokenizer, open('tokenizer.p', 'wb'))\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "Vocab_size #The size of our vocabulary is 7577 words.\n",
        "#calculate maximum length of descriptions to decide the model structure parameters.\n",
        "def max_length(descriptions):\n",
        "   desc_list = dict_to_list(descriptions)\n",
        "   return max(len(d.split()) for d in desc_list)\n",
        "max_length = max_length(descriptions)\n",
        "Max_length #Max_length of description is 32"
      ],
      "metadata": {
        "id": "ntHbv98z56GU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data generator, used by model.fit_generator()\n",
        "def data_generator(descriptions, features, tokenizer, max_length):\n",
        "    while 1:\n",
        "      for key, description_list in descriptions.items():\n",
        "          #retrieve photo features\n",
        "          feature = features[key][0]\n",
        "          inp_image, inp_seq, op_word = create_sequences(tokenizer, max_length, description_list, feature)\n",
        "          yield [[inp_image, inp_sequence], op_word]\n",
        "def create_sequences(tokenizer, max_length, desc_list, feature):\n",
        "    x_1, x_2, y = list(), list(), list()\n",
        "  # move through each description for the image\n",
        "    for desc in desc_list:\n",
        "      # encode the sequence\n",
        "       seq = tokenizer.texts_to_sequences([desc])[0]\n",
        "      # divide one sequence into various X,y pairs\n",
        "    for i in range(1, len(seq)):\n",
        "          # divide into input and output pair\n",
        "        in_seq, out_seq = seq[:i], seq[i]\n",
        "          # pad input sequence\n",
        "        in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "          # encode output sequence\n",
        "        out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
        "          # store\n",
        "        x_1.append(feature)\n",
        "        x_2.append(in_seq)\n",
        "        y.append(out_seq)\n",
        "      return np.array(X_1), np.array(X_2), np.array(y)\n",
        "#To check the shape of the input and output for your model\n",
        "[a,b],c = next(data_generator(train_descriptions, features, tokenizer, max_length))\n",
        "a.shape, b.shape, c.shape\n",
        "#((47, 2048), (47, 32), (47, 7577))"
      ],
      "metadata": {
        "id": "XBePZpC26x4P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}